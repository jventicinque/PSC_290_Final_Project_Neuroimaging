##Thresholding Walkthrough

#Load in Packages
from nilearn import plotting
import pylab as plt
%matplotlib inline
import numpy as np
from nilearn import image
import nibabel as nib
from nilearn.input_data import NiftiMasker

#Load in data
unthresh_data = nib.load('zstat4.nii.gz')
print(unthresh_data)

##Let's visualize the data first and then we will run some different thresholding techniques on it
#plot data
plotting.plot_roi(unthresh_data,
                 cmap='Paired', title='Unthreshholded Data', draw_cross=False)


##First, we need to make a mask of the whole brain and determine the number of voxels in data (this will be count as the "number of tests" that are being run).

#Make a mask of only voxels in the brain
from nilearn.masking import compute_epi_mask
mask_img = compute_epi_mask(unthresh_data)

#load in a mask of the mPFC
mask_file = 'mPFC_Bilateral_-8_54_24.nii'

#Visualize mask on thresholded data and MNI template
plotting.plot_roi(mask_file, bg_img= unthresh_data,
                 cmap='Paired', title='ROI of mPFC', draw_cross=False)

# create the mask to use and standardize
masker = NiftiMasker(mask_img=mask_file, standardize=True)
# fit the mask
thresh_masked = masker.fit_transform(unthresh_data)

#Determine the shape of the mask to see how many "independent tests" are being run
thresh_masked.shape

##This tells us that 515 voxels are in the current mask, so we use this as if we have 515 "independent tests"
#Assign the number of voxels in the mask to "n"
n = thresh_masked.shape[1]
print(n)

##Bonferonni Correction
#Is this test too conservative for neuroimaging data?
#bonferonni = alpha/ number of voxels 

def bonferroni_thresh(alpha = .05, n):
  return alpha / n

print(bonferroni_thresh(.05, n))

#plot to demonstrate bonferonni 
##example from online- grid width needs to be number of voxels.
grid_width = 100
threshold = 0.05/(grid_width**2)
simulation = SimulateGrid(grid_width=grid_width, n_subjects=20)
simulation.plot_grid_simulation(threshold=threshold, threshold_type='p', n_simulations=100)


#Family Wise Error Rate
#Is each test independent? Likely not, as there is some degree of spatial correlation

#Calculate FWER

#plot FWER

#False Discovery Rate
#The FDR is the expected proportion of false positives among significant tests.

import scipy.stats as sst
normal_distribution = sst.norm(loc=0,scale=1.) #loc is the mean, scale is the variance.
# The normal CDF
p_values = normal_distribution.cdf(z_values)

#plot FDR
